{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object tracking,before marking/detection manually(Single tracker)\n",
    "\n",
    "\n",
    "import cv2\n",
    "import sys\n",
    " \n",
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    " \n",
    "if __name__ == '__main__' :\n",
    " \n",
    "    # Set up tracker.\n",
    "    # Instead of MIL, you can also use\n",
    " \n",
    "    tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "    tracker_type = tracker_types[5]\n",
    " \n",
    "    if int(minor_ver) < 3:\n",
    "        tracker = cv2.Tracker_create(tracker_type)\n",
    "    else:\n",
    "        if tracker_type == 'BOOSTING':\n",
    "            tracker = cv2.TrackerBoosting_create()\n",
    "        if tracker_type == 'MIL':\n",
    "            tracker = cv2.TrackerMIL_create()\n",
    "        if tracker_type == 'KCF':\n",
    "            tracker = cv2.TrackerKCF_create()\n",
    "        if tracker_type == 'TLD':\n",
    "            tracker = cv2.TrackerTLD_create()\n",
    "        if tracker_type == 'MEDIANFLOW':\n",
    "            tracker = cv2.TrackerMedianFlow_create()\n",
    "        if tracker_type == 'GOTURN':\n",
    "            tracker = cv2.TrackerGOTURN_create()\n",
    "        if tracker_type == 'MOSSE':\n",
    "            tracker = cv2.TrackerMOSSE_create()\n",
    "        if tracker_type == \"CSRT\":\n",
    "            tracker = cv2.TrackerCSRT_create()\n",
    " \n",
    "    # Read video\n",
    "    #video = cv2.VideoCapture(\"Cheetah walking - 4K clip.mp4\")  \n",
    "    video = cv2.VideoCapture(\"c_s.mp4\")\n",
    " \n",
    "    # Exit if video not opened.\n",
    "    if not video.isOpened():\n",
    "        print (\"Could not open video\")\n",
    "        sys.exit()\n",
    " \n",
    "    # Read first frame.\n",
    "    ok, frame = video.read()\n",
    "    if not ok:\n",
    "        print('Cannot read video file')\n",
    "        sys.exit()\n",
    "     \n",
    "    # Define an initial bounding box\n",
    "    bbox = (287, 23, 86, 320)\n",
    " \n",
    "    # Uncomment the line below to select a different bounding box\n",
    "    bbox = cv2.selectROI(frame, False)\n",
    " \n",
    "    # Initialize tracker with first frame and bounding box\n",
    "    ok = tracker.init(frame, bbox)\n",
    " \n",
    "    while True:\n",
    "        # Read a new frame\n",
    "        ok, frame = video.read()\n",
    "        if not ok:\n",
    "            break\n",
    "         \n",
    "        # Start timer\n",
    "        timer = cv2.getTickCount()\n",
    " \n",
    "        # Update tracker\n",
    "        ok, bbox = tracker.update(frame)\n",
    " \n",
    "        # Calculate Frames per second (FPS)\n",
    "        fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer);\n",
    " \n",
    "        # Draw bounding box\n",
    "        if ok:\n",
    "            # Tracking success\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "        else :\n",
    "            # Tracking failure\n",
    "            cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    " \n",
    "        # Display tracker type on frame\n",
    "        cv2.putText(frame, tracker_type + \" Tracker\", (100,20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50),2);\n",
    "     \n",
    "        # Display FPS on frame\n",
    "        cv2.putText(frame, \"FPS : \" + str(int(fps)), (100,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50), 2);\n",
    " \n",
    "        # Display result\n",
    "        cv2.imshow(\"Tracking\", frame)\n",
    " \n",
    "        # Exit if ESC pressed\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27 : break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object tracking,before marking/detection manually(Multiple object tracker)\n",
    "\n",
    "#For starting the box steps :- Press enter -> Press any key to take boxes -> Press enter -> Press any key to take boxes \n",
    "#    -> Contunue it for taking boxes -> For stop and start detecting press q.\n",
    "    \n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import cv2\n",
    "from random import randint\n",
    " \n",
    "trackerTypes = ['BOOSTING', 'MIL', 'KCF','TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    " \n",
    "def createTrackerByName(trackerType):\n",
    "  # Create a tracker based on tracker name\n",
    "  if trackerType == trackerTypes[0]:\n",
    "    tracker = cv2.TrackerBoosting_create()\n",
    "  elif trackerType == trackerTypes[1]: \n",
    "    tracker = cv2.TrackerMIL_create()\n",
    "  elif trackerType == trackerTypes[2]:\n",
    "    tracker = cv2.TrackerKCF_create()\n",
    "  elif trackerType == trackerTypes[3]:\n",
    "    tracker = cv2.TrackerTLD_create()\n",
    "  elif trackerType == trackerTypes[4]:\n",
    "    tracker = cv2.TrackerMedianFlow_create()\n",
    "  elif trackerType == trackerTypes[5]:\n",
    "    tracker = cv2.TrackerGOTURN_create()\n",
    "  elif trackerType == trackerTypes[6]:\n",
    "    tracker = cv2.TrackerMOSSE_create()\n",
    "  elif trackerType == trackerTypes[7]:\n",
    "    tracker = cv2.TrackerCSRT_create()\n",
    "  else:\n",
    "    tracker = None\n",
    "    print('Incorrect tracker name')\n",
    "    print('Available trackers are:')\n",
    "    for t in trackerTypes:\n",
    "\n",
    "      print(t)\n",
    "     \n",
    "  return tracker\n",
    "\n",
    "\n",
    "# Set video to load\n",
    "videoPath = \"Cheetah walking - 4K clip.mp4\"\n",
    " \n",
    "# Create a video capture object to read videos\n",
    "cap = cv2.VideoCapture(videoPath)\n",
    " \n",
    "# Read first frame\n",
    "success, frame = cap.read()\n",
    "# quit if unable to read the video file\n",
    "if not success:\n",
    "  print('Failed to read video')\n",
    "  sys.exit(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "## Select boxes\n",
    "bboxes = []\n",
    "colors = [] \n",
    " \n",
    "# OpenCV's selectROI function doesn't work for selecting multiple objects in Python\n",
    "# So we will call this function in a loop till we are done selecting all objects\n",
    "while True:\n",
    "  # draw bounding boxes over objects\n",
    "  # selectROI's default behaviour is to draw box starting from the center\n",
    "  # when fromCenter is set to false, you can draw box starting from top left corner\n",
    "  bbox = cv2.selectROI('MultiTracker', frame)\n",
    "  bboxes.append(bbox)\n",
    "  colors.append((randint(0, 255), randint(0, 255), randint(0, 255)))\n",
    "  print(\"Press q to quit selecting boxes and start tracking\")\n",
    "  print(\"Press any other key to select next object\")\n",
    "  k = cv2.waitKey(0) & 0xFF\n",
    "  if (k == 113):  # q is pressed\n",
    "    break\n",
    " \n",
    "print('Selected bounding boxes {}'.format(bboxes))\n",
    "\n",
    "\n",
    "# Specify the tracker type\n",
    "trackerType = \"CSRT\"   \n",
    " \n",
    "# Create MultiTracker object\n",
    "multiTracker = cv2.MultiTracker_create()\n",
    " \n",
    "# Initialize MultiTracker \n",
    "for bbox in bboxes:\n",
    "  multiTracker.add(createTrackerByName(trackerType), frame, bbox)\n",
    "\n",
    "\n",
    "# Process video and track objects\n",
    "while cap.isOpened():\n",
    "  success, frame = cap.read()\n",
    "  if not success:\n",
    "    break\n",
    "   \n",
    "  # get updated location of objects in subsequent frames\n",
    "  success, boxes = multiTracker.update(frame)\n",
    " \n",
    "  # draw tracked objects\n",
    "  for i, newbox in enumerate(boxes):\n",
    "    p1 = (int(newbox[0]), int(newbox[1]))\n",
    "    p2 = (int(newbox[0] + newbox[2]), int(newbox[1] + newbox[3]))\n",
    "    cv2.rectangle(frame, p1, p2, colors[i], 2, 1)\n",
    " \n",
    "  # show frame\n",
    "  cv2.imshow('MultiTracker', frame)\n",
    "   \n",
    " \n",
    "  # quit on ESC button\n",
    "  if cv2.waitKey(1) & 0xFF == 27:  # Esc pressed\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object tracking,before marking/detection manually(Single tracker using GOTURN)\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import cv2\n",
    "from random import randint\n",
    "\n",
    "tracker = cv2.TrackerGOTURN_create()  \n",
    "\n",
    "\n",
    "# Read video\n",
    "video = cv2.VideoCapture(\"Cheetah walking - 4K clip.mp4\")\n",
    " \n",
    "# Exit if video not opened\n",
    "if not video.isOpened():\n",
    "    print(\"Could not open video\")\n",
    "    sys.exit()\n",
    " \n",
    "# Read first frame\n",
    "ok,frame = video.read()\n",
    "if not ok:\n",
    "    print(\"Cannot read video file\")\n",
    "    sys.exit()\n",
    "\n",
    "    \n",
    "# Define a bounding box\n",
    "bbox = (276, 23, 86, 320)\n",
    "  \n",
    "# Uncomment the line below to select a different bounding box\n",
    "#bbox = cv2.selectROI(frame, False)\n",
    "\n",
    "\n",
    "# Initialize tracker with first frame and bounding box\n",
    "ok = tracker.init(frame,bbox)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ok, frame = video.read()\n",
    "    if not ok:\n",
    "        break\n",
    " \n",
    "    # Start timer\n",
    "    timer = cv2.getTickCount()\n",
    " \n",
    "    # Update tracker\n",
    "    ok, bbox = tracker.update(frame)\n",
    " \n",
    "    # Calculate Frames per second (FPS)\n",
    "    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer);\n",
    " \n",
    "    # Draw bounding box\n",
    "    if ok:\n",
    "        # Tracking success\n",
    "        p1 = (int(bbox[0]), int(bbox[1]))\n",
    "        p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "        cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "    else :\n",
    "        # Tracking failure\n",
    "        cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    " \n",
    "    # Display tracker type on frame\n",
    "    cv2.putText(frame, \"GOTURN Tracker\", (100,20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50),2);\n",
    " \n",
    "    # Display FPS on frame\n",
    "    cv2.putText(frame, \"FPS : \" + str(int(fps)), (100,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50), 2);\n",
    " \n",
    "    # Display result\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "  \n",
    "    # Exit if ESC pressed\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    if k == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.4) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f5188314c33a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m   \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m   \u001b[1;31m# Convert current frame to grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m   \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m   \u001b[1;31m# Calculate absolute difference of current frame and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m   \u001b[1;31m# the median frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.4) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#Simple Background Estimation in Videos using OpenCV (C++/Python)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import data, filters\n",
    " \n",
    "# Open Video\n",
    "cap = cv2.VideoCapture('Video_output_1.avi')\n",
    " \n",
    "# Randomly select 25 frames\n",
    "frameIds = cap.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=25)\n",
    " \n",
    "# Store selected frames in an array\n",
    "frames = []\n",
    "for fid in frameIds:\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, fid)\n",
    "    ret, frame = cap.read()\n",
    "    frames.append(frame)\n",
    " \n",
    "# Calculate the median along the time axis\n",
    "medianFrame = np.median(frames, axis=0).astype(dtype=np.uint8)    \n",
    " \n",
    "# Display median frame\n",
    "cv2.imshow('frame', medianFrame)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "\n",
    "# Reset frame number to 0\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    " \n",
    "# Convert background to grayscale\n",
    "grayMedianFrame = cv2.cvtColor(medianFrame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# Loop over all frames\n",
    "ret = True\n",
    "while(ret):\n",
    " \n",
    "  # Read frame\n",
    "  ret, frame = cap.read()\n",
    "  # Convert current frame to grayscale\n",
    "  frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "  # Calculate absolute difference of current frame and \n",
    "  # the median frame\n",
    "  dframe = cv2.absdiff(frame, grayMedianFrame)\n",
    "  # Treshold to binarize\n",
    "  th, dframe = cv2.threshold(dframe, 30, 255, cv2.THRESH_BINARY)\n",
    "  # Display image\n",
    "  cv2.imshow('frame', dframe)\n",
    "  cv2.waitKey(20)\n",
    " \n",
    "# Release video object\n",
    "cap.release()\n",
    " \n",
    "# Destroy all windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret = True W = 1280 H = 720 channel = 3\n"
     ]
    }
   ],
   "source": [
    "#RGB to Grayscale(B/W) videos\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('c.mp4')\n",
    "\n",
    "ret, frame = cap.read()\n",
    "print('ret =', ret, 'W =', frame.shape[1], 'H =', frame.shape[0], 'channel =', frame.shape[2])\n",
    "\n",
    "\n",
    "FPS= 20.0\n",
    "FrameSize=(frame.shape[1], frame.shape[0])\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "\n",
    "out = cv2.VideoWriter('Video_output.avi', fourcc, FPS, FrameSize, 0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # check for successfulness of cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = gray\n",
    "\n",
    "    # Save the video\n",
    "    out.write(frame)\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "         break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8cf64d6836e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvgg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msqueezenet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0minception\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\alexnet.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_zoo\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmodel_zoo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'AlexNet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'alexnet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# or there is risk that later c modules will segfault when importing numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_np\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m     \u001b[0m_sanity_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0m_sanity_check\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m_sanity_check\u001b[1;34m()\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
